{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s41abKHFdSnk",
        "outputId": "f1909e8d-ad98-424d-b3fd-677bf93e4a29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load data\n",
        "with open('/content/drive/MyDrive/cs-project dataset/intents.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Context management class\n",
        "class ChatbotWithContext:\n",
        "    def __init__(self):\n",
        "        self.context = {}\n",
        "        self.last_topic = None\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.model = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def train(self, data):\n",
        "        patterns = []\n",
        "        tags = []\n",
        "        for intent in data['intents']:\n",
        "            for pattern in intent['patterns']:\n",
        "                patterns.append(pattern)\n",
        "                tags.append(intent['tag'])\n",
        "\n",
        "        # Preprocess\n",
        "        self.tokenizer.fit_on_texts(patterns)\n",
        "        X = self.tokenizer.texts_to_sequences(patterns)\n",
        "        X = pad_sequences(X)\n",
        "        y = self.label_encoder.fit_transform(tags)\n",
        "\n",
        "        # Build model\n",
        "        self.model = Sequential([\n",
        "            Embedding(len(self.tokenizer.word_index) + 1, 128, input_length=X.shape[1]),\n",
        "            LSTM(64),\n",
        "            Dense(16, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(len(set(tags)), activation='softmax')\n",
        "        ])\n",
        "\n",
        "        self.model.compile(optimizer='adam',\n",
        "                         loss='sparse_categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "        # Train\n",
        "        self.model.fit(X, y, epochs=200, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    def predict_response(self, text):\n",
        "        # Preprocess input\n",
        "        X_test = self.tokenizer.texts_to_sequences([text])\n",
        "        X_test = pad_sequences(X_test, maxlen=self.model.input_shape[1])\n",
        "\n",
        "        # Get prediction\n",
        "        prediction = self.model.predict(X_test)\n",
        "        predicted_tag = self.label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "\n",
        "        # Update context\n",
        "        current_topic = predicted_tag[0]\n",
        "        self.context.update({\n",
        "            'last_topic': self.last_topic,\n",
        "            'current_topic': current_topic\n",
        "        })\n",
        "        self.last_topic = current_topic\n",
        "\n",
        "        # Get response\n",
        "        for intent in data['intents']:\n",
        "            if intent['tag'] == predicted_tag[0]:\n",
        "                response = np.random.choice(intent['responses'])\n",
        "                return self.validate_response(text, response)\n",
        "\n",
        "        return \"I'm not sure how to respond to that.\"\n",
        "\n",
        "    def validate_response(self, text, response):\n",
        "        if len(response.split()) < 3:  # Too short\n",
        "            return self.get_fallback_response()\n",
        "        return response\n",
        "\n",
        "    def get_fallback_response(self):\n",
        "        return \"Could you please provide more details about your question?\"\n",
        "\n",
        "# Usage\n",
        "chatbot = ChatbotWithContext()\n",
        "chatbot.train(data)\n",
        "\n",
        "# Interactive loop\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    response = chatbot.predict_response(user_input)\n",
        "    print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f27GLsqDdMhl",
        "outputId": "fd3706a3-8128-4d6f-cca3-783d7b8f502f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.1052 - loss: 3.1677 - val_accuracy: 0.0000e+00 - val_loss: 3.1641\n",
            "Epoch 2/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1930 - loss: 3.1135 - val_accuracy: 0.0000e+00 - val_loss: 3.1426\n",
            "Epoch 3/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1803 - loss: 3.0252 - val_accuracy: 0.0000e+00 - val_loss: 3.0988\n",
            "Epoch 4/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2008 - loss: 2.9345 - val_accuracy: 0.0000e+00 - val_loss: 3.0645\n",
            "Epoch 5/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1982 - loss: 2.8589 - val_accuracy: 0.0000e+00 - val_loss: 3.1167\n",
            "Epoch 6/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1978 - loss: 2.9258 - val_accuracy: 0.0000e+00 - val_loss: 3.2082\n",
            "Epoch 7/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2689 - loss: 2.6786 - val_accuracy: 0.0000e+00 - val_loss: 3.2450\n",
            "Epoch 8/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2863 - loss: 2.6215 - val_accuracy: 0.0000e+00 - val_loss: 3.2578\n",
            "Epoch 9/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2858 - loss: 2.5361 - val_accuracy: 0.0000e+00 - val_loss: 3.2915\n",
            "Epoch 10/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3243 - loss: 2.5132 - val_accuracy: 0.0000e+00 - val_loss: 3.3209\n",
            "Epoch 11/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2365 - loss: 2.5633 - val_accuracy: 0.0000e+00 - val_loss: 3.2959\n",
            "Epoch 12/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3275 - loss: 2.3201 - val_accuracy: 0.0000e+00 - val_loss: 3.3939\n",
            "Epoch 13/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4523 - loss: 2.1485 - val_accuracy: 0.0000e+00 - val_loss: 3.4494\n",
            "Epoch 14/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3971 - loss: 2.1825 - val_accuracy: 0.0000e+00 - val_loss: 3.4375\n",
            "Epoch 15/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2942 - loss: 2.3033 - val_accuracy: 0.0000e+00 - val_loss: 3.4342\n",
            "Epoch 16/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3741 - loss: 2.1426 - val_accuracy: 0.0000e+00 - val_loss: 3.4427\n",
            "Epoch 17/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4085 - loss: 2.0990 - val_accuracy: 0.0000e+00 - val_loss: 3.4767\n",
            "Epoch 18/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4017 - loss: 2.0365 - val_accuracy: 0.0000e+00 - val_loss: 3.5034\n",
            "Epoch 19/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4132 - loss: 2.0571 - val_accuracy: 0.0000e+00 - val_loss: 3.5824\n",
            "Epoch 20/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4124 - loss: 1.9922 - val_accuracy: 0.0000e+00 - val_loss: 3.5935\n",
            "Epoch 21/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4093 - loss: 2.0780 - val_accuracy: 0.0000e+00 - val_loss: 3.6133\n",
            "Epoch 22/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4466 - loss: 1.8272 - val_accuracy: 0.0000e+00 - val_loss: 3.7421\n",
            "Epoch 23/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4384 - loss: 1.7835 - val_accuracy: 0.0000e+00 - val_loss: 3.7551\n",
            "Epoch 24/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4150 - loss: 1.8915 - val_accuracy: 0.0000e+00 - val_loss: 3.8620\n",
            "Epoch 25/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4092 - loss: 1.7664 - val_accuracy: 0.0000e+00 - val_loss: 3.7645\n",
            "Epoch 26/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4860 - loss: 1.7617 - val_accuracy: 0.0000e+00 - val_loss: 4.0680\n",
            "Epoch 27/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4374 - loss: 1.7447 - val_accuracy: 0.0000e+00 - val_loss: 3.9409\n",
            "Epoch 28/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4623 - loss: 1.6539 - val_accuracy: 0.0000e+00 - val_loss: 4.2181\n",
            "Epoch 29/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5394 - loss: 1.5781 - val_accuracy: 0.0000e+00 - val_loss: 4.1396\n",
            "Epoch 30/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5199 - loss: 1.5288 - val_accuracy: 0.0000e+00 - val_loss: 4.2593\n",
            "Epoch 31/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5057 - loss: 1.6277 - val_accuracy: 0.0000e+00 - val_loss: 4.4184\n",
            "Epoch 32/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5125 - loss: 1.4466 - val_accuracy: 0.0000e+00 - val_loss: 4.3680\n",
            "Epoch 33/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5097 - loss: 1.5100 - val_accuracy: 0.0000e+00 - val_loss: 4.6137\n",
            "Epoch 34/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5032 - loss: 1.5563 - val_accuracy: 0.0000e+00 - val_loss: 4.3801\n",
            "Epoch 35/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4975 - loss: 1.4816 - val_accuracy: 0.0000e+00 - val_loss: 4.3962\n",
            "Epoch 36/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5173 - loss: 1.4231 - val_accuracy: 0.0000e+00 - val_loss: 4.6519\n",
            "Epoch 37/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5670 - loss: 1.3733 - val_accuracy: 0.0000e+00 - val_loss: 4.6262\n",
            "Epoch 38/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5194 - loss: 1.4018 - val_accuracy: 0.0000e+00 - val_loss: 4.7756\n",
            "Epoch 39/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5408 - loss: 1.3793 - val_accuracy: 0.0000e+00 - val_loss: 4.7607\n",
            "Epoch 40/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5552 - loss: 1.3134 - val_accuracy: 0.0000e+00 - val_loss: 4.7200\n",
            "Epoch 41/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4991 - loss: 1.4106 - val_accuracy: 0.0000e+00 - val_loss: 4.6298\n",
            "Epoch 42/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5543 - loss: 1.2849 - val_accuracy: 0.0000e+00 - val_loss: 4.8259\n",
            "Epoch 43/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6032 - loss: 1.3023 - val_accuracy: 0.0000e+00 - val_loss: 5.0141\n",
            "Epoch 44/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5292 - loss: 1.3078 - val_accuracy: 0.0000e+00 - val_loss: 5.0101\n",
            "Epoch 45/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6015 - loss: 1.1530 - val_accuracy: 0.0000e+00 - val_loss: 5.0723\n",
            "Epoch 46/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6062 - loss: 1.1377 - val_accuracy: 0.0000e+00 - val_loss: 5.2371\n",
            "Epoch 47/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5909 - loss: 1.1976 - val_accuracy: 0.0000e+00 - val_loss: 5.2208\n",
            "Epoch 48/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6176 - loss: 1.2007 - val_accuracy: 0.0000e+00 - val_loss: 5.4082\n",
            "Epoch 49/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6032 - loss: 1.1232 - val_accuracy: 0.0000e+00 - val_loss: 5.1767\n",
            "Epoch 50/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5778 - loss: 1.1230 - val_accuracy: 0.0000e+00 - val_loss: 5.2876\n",
            "Epoch 51/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6251 - loss: 1.1297 - val_accuracy: 0.0000e+00 - val_loss: 5.3481\n",
            "Epoch 52/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7250 - loss: 0.9075 - val_accuracy: 0.0000e+00 - val_loss: 5.5616\n",
            "Epoch 53/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6482 - loss: 1.1090 - val_accuracy: 0.0000e+00 - val_loss: 5.7542\n",
            "Epoch 54/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6462 - loss: 1.1142 - val_accuracy: 0.0000e+00 - val_loss: 5.5281\n",
            "Epoch 55/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6721 - loss: 1.0387 - val_accuracy: 0.0000e+00 - val_loss: 5.3589\n",
            "Epoch 56/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6782 - loss: 1.0115 - val_accuracy: 0.0000e+00 - val_loss: 5.7515\n",
            "Epoch 57/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7655 - loss: 0.8533 - val_accuracy: 0.0000e+00 - val_loss: 5.8976\n",
            "Epoch 58/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6367 - loss: 1.0397 - val_accuracy: 0.0000e+00 - val_loss: 5.9767\n",
            "Epoch 59/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6134 - loss: 1.1057 - val_accuracy: 0.0000e+00 - val_loss: 6.0001\n",
            "Epoch 60/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5810 - loss: 1.1284 - val_accuracy: 0.0000e+00 - val_loss: 6.1729\n",
            "Epoch 61/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7290 - loss: 0.8248 - val_accuracy: 0.0000e+00 - val_loss: 6.0046\n",
            "Epoch 62/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6809 - loss: 0.9748 - val_accuracy: 0.0000e+00 - val_loss: 6.0986\n",
            "Epoch 63/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6681 - loss: 0.8757 - val_accuracy: 0.0000e+00 - val_loss: 6.1703\n",
            "Epoch 64/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7050 - loss: 0.7964 - val_accuracy: 0.0000e+00 - val_loss: 6.2198\n",
            "Epoch 65/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6761 - loss: 0.9860 - val_accuracy: 0.0000e+00 - val_loss: 6.4383\n",
            "Epoch 66/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6983 - loss: 0.9245 - val_accuracy: 0.0000e+00 - val_loss: 6.1434\n",
            "Epoch 67/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7219 - loss: 0.8744 - val_accuracy: 0.0000e+00 - val_loss: 6.3205\n",
            "Epoch 68/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6149 - loss: 1.0473 - val_accuracy: 0.0000e+00 - val_loss: 6.4915\n",
            "Epoch 69/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7206 - loss: 0.8104 - val_accuracy: 0.0000e+00 - val_loss: 6.5083\n",
            "Epoch 70/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6668 - loss: 0.9294 - val_accuracy: 0.0000e+00 - val_loss: 6.7401\n",
            "Epoch 71/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7012 - loss: 0.8675 - val_accuracy: 0.0000e+00 - val_loss: 6.6469\n",
            "Epoch 72/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6791 - loss: 0.9026 - val_accuracy: 0.0000e+00 - val_loss: 6.4332\n",
            "Epoch 73/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6413 - loss: 0.9995 - val_accuracy: 0.0000e+00 - val_loss: 6.3077\n",
            "Epoch 74/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7189 - loss: 0.7821 - val_accuracy: 0.0000e+00 - val_loss: 6.4325\n",
            "Epoch 75/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7072 - loss: 0.8600 - val_accuracy: 0.0000e+00 - val_loss: 6.7619\n",
            "Epoch 76/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7020 - loss: 0.8111 - val_accuracy: 0.0000e+00 - val_loss: 6.6211\n",
            "Epoch 77/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7027 - loss: 0.8539 - val_accuracy: 0.0000e+00 - val_loss: 6.4319\n",
            "Epoch 78/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7117 - loss: 0.8200 - val_accuracy: 0.0000e+00 - val_loss: 6.7830\n",
            "Epoch 79/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7133 - loss: 0.8341 - val_accuracy: 0.0000e+00 - val_loss: 7.1039\n",
            "Epoch 80/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7660 - loss: 0.6824 - val_accuracy: 0.0250 - val_loss: 6.9342\n",
            "Epoch 81/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6828 - loss: 0.8746 - val_accuracy: 0.0000e+00 - val_loss: 6.9295\n",
            "Epoch 82/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7403 - loss: 0.7511 - val_accuracy: 0.0000e+00 - val_loss: 6.9530\n",
            "Epoch 83/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7625 - loss: 0.7247 - val_accuracy: 0.0250 - val_loss: 6.8239\n",
            "Epoch 84/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7633 - loss: 0.6843 - val_accuracy: 0.0000e+00 - val_loss: 7.3037\n",
            "Epoch 85/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6970 - loss: 0.8508 - val_accuracy: 0.0000e+00 - val_loss: 7.2336\n",
            "Epoch 86/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7573 - loss: 0.6990 - val_accuracy: 0.0000e+00 - val_loss: 7.1470\n",
            "Epoch 87/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7704 - loss: 0.6355 - val_accuracy: 0.0000e+00 - val_loss: 6.9608\n",
            "Epoch 88/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7752 - loss: 0.6195 - val_accuracy: 0.0250 - val_loss: 7.0372\n",
            "Epoch 89/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6737 - loss: 0.8492 - val_accuracy: 0.0250 - val_loss: 7.4479\n",
            "Epoch 90/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7481 - loss: 0.7387 - val_accuracy: 0.0250 - val_loss: 7.3474\n",
            "Epoch 91/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6769 - loss: 0.8457 - val_accuracy: 0.0250 - val_loss: 7.1714\n",
            "Epoch 92/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7548 - loss: 0.7777 - val_accuracy: 0.0000e+00 - val_loss: 7.5876\n",
            "Epoch 93/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7406 - loss: 0.7662 - val_accuracy: 0.0250 - val_loss: 7.4850\n",
            "Epoch 94/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6967 - loss: 0.8005 - val_accuracy: 0.0000e+00 - val_loss: 7.7241\n",
            "Epoch 95/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7462 - loss: 0.7319 - val_accuracy: 0.0250 - val_loss: 7.6691\n",
            "Epoch 96/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6952 - loss: 0.8125 - val_accuracy: 0.0250 - val_loss: 7.6764\n",
            "Epoch 97/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7377 - loss: 0.7612 - val_accuracy: 0.0500 - val_loss: 7.4861\n",
            "Epoch 98/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7487 - loss: 0.7413 - val_accuracy: 0.0500 - val_loss: 7.3453\n",
            "Epoch 99/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7488 - loss: 0.6968 - val_accuracy: 0.0500 - val_loss: 7.4533\n",
            "Epoch 100/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8386 - loss: 0.5599 - val_accuracy: 0.0500 - val_loss: 7.4973\n",
            "Epoch 101/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7571 - loss: 0.6288 - val_accuracy: 0.0500 - val_loss: 7.3153\n",
            "Epoch 102/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7950 - loss: 0.6124 - val_accuracy: 0.0500 - val_loss: 7.5224\n",
            "Epoch 103/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7312 - loss: 0.7713 - val_accuracy: 0.0500 - val_loss: 7.6006\n",
            "Epoch 104/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7834 - loss: 0.5697 - val_accuracy: 0.0250 - val_loss: 7.9297\n",
            "Epoch 105/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7191 - loss: 0.7870 - val_accuracy: 0.0500 - val_loss: 7.8269\n",
            "Epoch 106/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7876 - loss: 0.5970 - val_accuracy: 0.0500 - val_loss: 7.5513\n",
            "Epoch 107/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7960 - loss: 0.6000 - val_accuracy: 0.0000e+00 - val_loss: 8.1998\n",
            "Epoch 108/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7225 - loss: 0.7594 - val_accuracy: 0.0250 - val_loss: 7.9720\n",
            "Epoch 109/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7307 - loss: 0.6759 - val_accuracy: 0.0500 - val_loss: 7.3192\n",
            "Epoch 110/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7604 - loss: 0.6426 - val_accuracy: 0.0500 - val_loss: 7.7861\n",
            "Epoch 111/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7644 - loss: 0.5799 - val_accuracy: 0.0500 - val_loss: 7.9310\n",
            "Epoch 112/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7208 - loss: 0.7224 - val_accuracy: 0.0500 - val_loss: 7.4344\n",
            "Epoch 113/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7640 - loss: 0.6553 - val_accuracy: 0.0500 - val_loss: 8.0708\n",
            "Epoch 114/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7842 - loss: 0.5595 - val_accuracy: 0.0500 - val_loss: 8.2716\n",
            "Epoch 115/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7725 - loss: 0.6293 - val_accuracy: 0.0500 - val_loss: 7.9348\n",
            "Epoch 116/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8347 - loss: 0.5488 - val_accuracy: 0.0500 - val_loss: 7.6959\n",
            "Epoch 117/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7998 - loss: 0.5890 - val_accuracy: 0.0500 - val_loss: 7.8839\n",
            "Epoch 118/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7913 - loss: 0.6411 - val_accuracy: 0.0500 - val_loss: 8.5001\n",
            "Epoch 119/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7981 - loss: 0.5751 - val_accuracy: 0.0500 - val_loss: 8.4575\n",
            "Epoch 120/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7262 - loss: 0.7309 - val_accuracy: 0.0250 - val_loss: 8.5422\n",
            "Epoch 121/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7806 - loss: 0.5608 - val_accuracy: 0.0000e+00 - val_loss: 8.6210\n",
            "Epoch 122/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7764 - loss: 0.6251 - val_accuracy: 0.0250 - val_loss: 8.5308\n",
            "Epoch 123/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7159 - loss: 0.6833 - val_accuracy: 0.0500 - val_loss: 8.4134\n",
            "Epoch 124/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7518 - loss: 0.6479 - val_accuracy: 0.0250 - val_loss: 8.6495\n",
            "Epoch 125/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7503 - loss: 0.6628 - val_accuracy: 0.0250 - val_loss: 8.9441\n",
            "Epoch 126/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7613 - loss: 0.6295 - val_accuracy: 0.0250 - val_loss: 8.6736\n",
            "Epoch 127/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7113 - loss: 0.7192 - val_accuracy: 0.0500 - val_loss: 8.2829\n",
            "Epoch 128/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7454 - loss: 0.5825 - val_accuracy: 0.0500 - val_loss: 8.3712\n",
            "Epoch 129/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7099 - loss: 0.7053 - val_accuracy: 0.0500 - val_loss: 8.4572\n",
            "Epoch 130/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7173 - loss: 0.6643 - val_accuracy: 0.0500 - val_loss: 8.4155\n",
            "Epoch 131/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7178 - loss: 0.6970 - val_accuracy: 0.0500 - val_loss: 8.5317\n",
            "Epoch 132/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7894 - loss: 0.5613 - val_accuracy: 0.0500 - val_loss: 8.4277\n",
            "Epoch 133/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7262 - loss: 0.6970 - val_accuracy: 0.0500 - val_loss: 8.4890\n",
            "Epoch 134/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7703 - loss: 0.5715 - val_accuracy: 0.0250 - val_loss: 8.7292\n",
            "Epoch 135/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7939 - loss: 0.5426 - val_accuracy: 0.0250 - val_loss: 8.7449\n",
            "Epoch 136/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8005 - loss: 0.5025 - val_accuracy: 0.0500 - val_loss: 8.6453\n",
            "Epoch 137/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7552 - loss: 0.6284 - val_accuracy: 0.0500 - val_loss: 8.6550\n",
            "Epoch 138/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7977 - loss: 0.4779 - val_accuracy: 0.0500 - val_loss: 8.8806\n",
            "Epoch 139/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7633 - loss: 0.6244 - val_accuracy: 0.0250 - val_loss: 9.1938\n",
            "Epoch 140/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7803 - loss: 0.5624 - val_accuracy: 0.0000e+00 - val_loss: 9.1405\n",
            "Epoch 141/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7308 - loss: 0.7008 - val_accuracy: 0.0000e+00 - val_loss: 8.9663\n",
            "Epoch 142/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7423 - loss: 0.6209 - val_accuracy: 0.0000e+00 - val_loss: 9.2882\n",
            "Epoch 143/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7305 - loss: 0.6381 - val_accuracy: 0.0250 - val_loss: 9.2764\n",
            "Epoch 144/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7637 - loss: 0.6491 - val_accuracy: 0.0500 - val_loss: 9.0815\n",
            "Epoch 145/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8212 - loss: 0.4819 - val_accuracy: 0.0000e+00 - val_loss: 9.2309\n",
            "Epoch 146/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7508 - loss: 0.6425 - val_accuracy: 0.0000e+00 - val_loss: 9.2727\n",
            "Epoch 147/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7842 - loss: 0.5725 - val_accuracy: 0.0000e+00 - val_loss: 9.4774\n",
            "Epoch 148/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7054 - loss: 0.6874 - val_accuracy: 0.0000e+00 - val_loss: 9.4405\n",
            "Epoch 149/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7566 - loss: 0.5842 - val_accuracy: 0.0000e+00 - val_loss: 9.3013\n",
            "Epoch 150/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7715 - loss: 0.5389 - val_accuracy: 0.0250 - val_loss: 9.3888\n",
            "Epoch 151/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7455 - loss: 0.6768 - val_accuracy: 0.0500 - val_loss: 9.5303\n",
            "Epoch 152/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7570 - loss: 0.5876 - val_accuracy: 0.0500 - val_loss: 9.1293\n",
            "Epoch 153/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7692 - loss: 0.6643 - val_accuracy: 0.0500 - val_loss: 8.5610\n",
            "Epoch 154/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7547 - loss: 0.6252 - val_accuracy: 0.0750 - val_loss: 8.4799\n",
            "Epoch 155/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7670 - loss: 0.5660 - val_accuracy: 0.0500 - val_loss: 8.9891\n",
            "Epoch 156/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8129 - loss: 0.4793 - val_accuracy: 0.0250 - val_loss: 9.5571\n",
            "Epoch 157/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7441 - loss: 0.7217 - val_accuracy: 0.0250 - val_loss: 9.5180\n",
            "Epoch 158/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7926 - loss: 0.5182 - val_accuracy: 0.0250 - val_loss: 9.3515\n",
            "Epoch 159/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8059 - loss: 0.5263 - val_accuracy: 0.0250 - val_loss: 9.7323\n",
            "Epoch 160/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8080 - loss: 0.5468 - val_accuracy: 0.0250 - val_loss: 9.8722\n",
            "Epoch 161/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7802 - loss: 0.5189 - val_accuracy: 0.0250 - val_loss: 9.3623\n",
            "Epoch 162/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7345 - loss: 0.6820 - val_accuracy: 0.0250 - val_loss: 9.0625\n",
            "Epoch 163/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7628 - loss: 0.5957 - val_accuracy: 0.0250 - val_loss: 9.3035\n",
            "Epoch 164/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8604 - loss: 0.4219 - val_accuracy: 0.0250 - val_loss: 9.6803\n",
            "Epoch 165/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7639 - loss: 0.6123 - val_accuracy: 0.0250 - val_loss: 9.7368\n",
            "Epoch 166/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7702 - loss: 0.5387 - val_accuracy: 0.0250 - val_loss: 9.4557\n",
            "Epoch 167/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7903 - loss: 0.5758 - val_accuracy: 0.0250 - val_loss: 9.3281\n",
            "Epoch 168/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8163 - loss: 0.5237 - val_accuracy: 0.0250 - val_loss: 9.3508\n",
            "Epoch 169/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7851 - loss: 0.5197 - val_accuracy: 0.0250 - val_loss: 9.4802\n",
            "Epoch 170/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8127 - loss: 0.5364 - val_accuracy: 0.0000e+00 - val_loss: 9.7418\n",
            "Epoch 171/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7682 - loss: 0.6572 - val_accuracy: 0.0000e+00 - val_loss: 9.4683\n",
            "Epoch 172/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7712 - loss: 0.5751 - val_accuracy: 0.0250 - val_loss: 9.7018\n",
            "Epoch 173/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7829 - loss: 0.5873 - val_accuracy: 0.0000e+00 - val_loss: 10.2973\n",
            "Epoch 174/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7874 - loss: 0.5229 - val_accuracy: 0.0500 - val_loss: 9.7841\n",
            "Epoch 175/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7844 - loss: 0.5843 - val_accuracy: 0.0500 - val_loss: 9.5567\n",
            "Epoch 176/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8124 - loss: 0.4998 - val_accuracy: 0.0500 - val_loss: 9.8133\n",
            "Epoch 177/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8139 - loss: 0.4278 - val_accuracy: 0.0250 - val_loss: 10.1924\n",
            "Epoch 178/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8126 - loss: 0.4696 - val_accuracy: 0.0250 - val_loss: 9.7798\n",
            "Epoch 179/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8550 - loss: 0.3793 - val_accuracy: 0.0500 - val_loss: 9.7715\n",
            "Epoch 180/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7717 - loss: 0.5893 - val_accuracy: 0.0250 - val_loss: 10.1195\n",
            "Epoch 181/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8015 - loss: 0.5560 - val_accuracy: 0.0500 - val_loss: 10.2068\n",
            "Epoch 182/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7401 - loss: 0.5764 - val_accuracy: 0.0250 - val_loss: 10.0684\n",
            "Epoch 183/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8193 - loss: 0.4469 - val_accuracy: 0.0500 - val_loss: 9.6876\n",
            "Epoch 184/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8228 - loss: 0.4664 - val_accuracy: 0.0500 - val_loss: 9.7939\n",
            "Epoch 185/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8134 - loss: 0.5508 - val_accuracy: 0.0500 - val_loss: 10.0717\n",
            "Epoch 186/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8058 - loss: 0.5337 - val_accuracy: 0.0500 - val_loss: 10.0744\n",
            "Epoch 187/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8397 - loss: 0.4546 - val_accuracy: 0.0500 - val_loss: 9.9030\n",
            "Epoch 188/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7907 - loss: 0.5782 - val_accuracy: 0.0500 - val_loss: 10.1003\n",
            "Epoch 189/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8027 - loss: 0.5228 - val_accuracy: 0.0250 - val_loss: 10.4371\n",
            "Epoch 190/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7847 - loss: 0.5716 - val_accuracy: 0.0500 - val_loss: 10.1782\n",
            "Epoch 191/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8461 - loss: 0.5365 - val_accuracy: 0.0750 - val_loss: 9.9180\n",
            "Epoch 192/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8251 - loss: 0.4352 - val_accuracy: 0.0750 - val_loss: 9.8944\n",
            "Epoch 193/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7324 - loss: 0.6817 - val_accuracy: 0.0500 - val_loss: 10.1913\n",
            "Epoch 194/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8226 - loss: 0.4750 - val_accuracy: 0.0250 - val_loss: 10.3686\n",
            "Epoch 195/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8601 - loss: 0.4083 - val_accuracy: 0.0250 - val_loss: 10.2451\n",
            "Epoch 196/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7635 - loss: 0.5612 - val_accuracy: 0.0250 - val_loss: 9.9379\n",
            "Epoch 197/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7063 - loss: 0.6058 - val_accuracy: 0.0250 - val_loss: 10.2991\n",
            "Epoch 198/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7548 - loss: 0.6129 - val_accuracy: 0.0250 - val_loss: 10.4837\n",
            "Epoch 199/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8381 - loss: 0.4345 - val_accuracy: 0.0250 - val_loss: 10.4460\n",
            "Epoch 200/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7962 - loss: 0.5082 - val_accuracy: 0.0250 - val_loss: 10.1141\n",
            "You: hello\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "Bot: I'm here to assist you, what can I do for you today?\n",
            "You: Good evening\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Bot: I'm here to answer your questions, what would you like to know?\n",
            "You: Hey\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Bot: Yo, what can I do for you?\n",
            "You: Hi\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Bot: I'm here to assist you, what can I do for you today?\n",
            "You: what\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Bot: How may I be of assistance today?\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Save the model and tokenizer\n",
        "chatbot.model.save('chatbot_model.keras')  # Save the model\n",
        "with open('tokenizer.pickle', 'wb') as handle:  # Save the tokenizer\n",
        "    pickle.dump(chatbot.tokenizer, handle)\n",
        "\n",
        "# Load the model and tokenizer\n",
        "chatbot.model = load_model('chatbot_model.keras')  # Load the model\n",
        "with open('tokenizer.pickle', 'rb') as handle:  # Load the tokenizer\n",
        "    chatbot.tokenizer = pickle.load(handle)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b1jRulydN4Z",
        "outputId": "0798f930-3ca6-4569-d8d6-8943639bb54e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ]
    }
  ]
}